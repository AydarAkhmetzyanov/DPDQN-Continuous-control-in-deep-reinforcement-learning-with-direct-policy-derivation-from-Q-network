{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [15, 10]\n",
    "time_steps = 1e6 #testrun\n",
    "#time_steps = 1000000 #for prod or even more *10?100?\n",
    "time_steps_test = int(time_steps/100)\n",
    "\n",
    "from stable_baselines.bench import Monitor\n",
    "from stable_baselines.results_plotter import load_results, ts2xy\n",
    "from stable_baselines import PPO2\n",
    "from stable_baselines import results_plotter\n",
    "from stable_baselines.common.policies import MlpPolicy\n",
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "from stable_baselines import A2C\n",
    "from stable_baselines import ACKTR\n",
    "from stable_baselines import HER\n",
    "from stable_baselines import SAC\n",
    "\n",
    "os.makedirs(\"logs_test\", exist_ok=True)\n",
    "os.makedirs(\"logs_train\", exist_ok=True)\n",
    "os.makedirs(\"logs_tmp\", exist_ok=True)\n",
    "from shutil import copyfile\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PPO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/aydarakhmetzyanov/anaconda3/envs/qlearning/lib/python3.6/site-packages/stable_baselines/common/tf_util.py:57: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/aydarakhmetzyanov/anaconda3/envs/qlearning/lib/python3.6/site-packages/stable_baselines/common/tf_util.py:66: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/aydarakhmetzyanov/anaconda3/envs/qlearning/lib/python3.6/site-packages/stable_baselines/common/policies.py:115: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/aydarakhmetzyanov/anaconda3/envs/qlearning/lib/python3.6/site-packages/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/aydarakhmetzyanov/anaconda3/envs/qlearning/lib/python3.6/site-packages/stable_baselines/common/policies.py:562: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /Users/aydarakhmetzyanov/anaconda3/envs/qlearning/lib/python3.6/site-packages/tensorflow_core/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /Users/aydarakhmetzyanov/anaconda3/envs/qlearning/lib/python3.6/site-packages/stable_baselines/a2c/utils.py:156: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/aydarakhmetzyanov/anaconda3/envs/qlearning/lib/python3.6/site-packages/stable_baselines/common/distributions.py:413: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/aydarakhmetzyanov/anaconda3/envs/qlearning/lib/python3.6/site-packages/stable_baselines/ppo2/ppo2.py:193: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/aydarakhmetzyanov/anaconda3/envs/qlearning/lib/python3.6/site-packages/stable_baselines/ppo2/ppo2.py:201: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/aydarakhmetzyanov/anaconda3/envs/qlearning/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /Users/aydarakhmetzyanov/anaconda3/envs/qlearning/lib/python3.6/site-packages/stable_baselines/ppo2/ppo2.py:209: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/aydarakhmetzyanov/anaconda3/envs/qlearning/lib/python3.6/site-packages/stable_baselines/ppo2/ppo2.py:243: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/aydarakhmetzyanov/anaconda3/envs/qlearning/lib/python3.6/site-packages/stable_baselines/ppo2/ppo2.py:245: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "time_steps_todo: 100000.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjgAAACICAYAAADqIJGqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO2debwcVZX4vyfJS/Ky5yWQhOwJCRAWQxJCQAZEwg4TUREUCe76U2cyzscFd3AdZRyN4gLCjCgqsgiigkgQBNQ8yCMBgoRsZE/I9pKXjazn98etSiqd6u6q7qru6n7n+/n0p7urblWdu58699x7RVUxDMMwDMOoJzpUWwDDMAzDMIykMQXHMAzDMIy6wxQcwzAMwzDqDlNwDMMwDMOoO0zBMQzDMAyj7jAFxzAMwzCMusMUHMMwqo6I3CAidyYd1jCM9ospOIZhFERElonILhHZLiKvicjPRKRHteWqBCLyHhHZ78W9TUTmichl3rk3icgB79w2EXlFRN4buLaLiHxTRFZ46bdIRD4lIhII89/e8W0iskBEplcjnoZRj5iCYxhGFC5X1R7ABGAS8IUqy1NJ/uHFvQ9wO3C3iPT1zq3xzvUCPgP8VETGeefuAc4DLgF6AtcCHwJmBu69A7gc6A1cB8wUkTNTjo9htAtMwTEMIzKquhp4GDhJRHqLyO0islZEVovI10SkIxy0fDztWShaReRVEbnYv4+IjBSRv3qWi0eB/oFzbxKRVcHnelakqbnyFAvrDWfdIyJ3es96UUTGishnRWS9iKwUkQsixv0A8L9AIzA655yq6gNAKzBORM4DLgDepqrzVXWfqs4G3g18TESO9a77sqouUNUDqtoMPAWcEUUewzAKYwqOYRiREZGhOIvEXOBnwD7gWOBUXIf+gUDw04FXcMrLt4HbA8MzvwJavHNfxVkv0uJy4BdAX0/uR3Bt32DgK8AtUW4iIp1w8dsOLMo510FErsBZeV4EzgeaVXVlMJynxKzCWXZy798InAa8FCNuhmHkoVO1BTAMoyZ4QET2AVuBPwK3AQuBPqq6C9ghIt/FDcH4CsNyVf0pgIjcAfwIGCAinXEd+VRV3Q08KSK/T1H2p1T1EU+Oe4C3Av+lqvtF5C7gVhHpo6pb8lw/RUS24JS5xcAVqrrV09WO8c4dAFYA16rqKyLSH1ib535rCVisAvwEeB6ngBmGUSam4BiGEYW3qOos/4+ITAYagLUBn9kOQNBisc7/oao7vXA9cJ17q6ruCIRdDgxNR3ReC/zeBWxU1f2B/wA9RORk3PAbOOXsRO/3bFU9K8+916jqkJDjG4Exea4Z5J0/iIjcBJwEnKu2A7JhJIIpOIZhlMJKYDfQX1X3xbx2LdBXRLoHlJxhgN+x7wC6+YE9v56j8twrTtiCqOpTOAUsCWYB/yEiQ4PDVCJyOk6R+0vg2I3AxcA5qtqW0PMNo91jPjiGYcRGVdcCfwa+IyK9PB+U0SJyToRrlwNzgBtFpLOInIXzk/FZCHQVkUtFpAE3Y6tLntvFCVsxPGvXY8B9InKiiHQUkSnAncCPVXURgIh8FngXbrhuU/UkNoz6wxQcwzBKZTrQGfgnbvbQvbjhlyi8C+eEvBn4MvBz/4SqbgU+ivPzWY2z0qwKuUessFXgbcDjwJ9wjsl34qaZ/1sgzDdw1qvF3no620XkcxWX1DDqELHhXsMwDMMw6g2z4BiGYRiGUXeYgmMYhmEYRt1RVMERkStFpKf3+wsi8lsRmZC+aIZhGIZhGKURxYLzRVXd5s10mIpzkvtxumIZhmEYhmGUTpR1cPwFsS4FblXVP4rI11KUqSL0799fR4wYUW0xDMMwDMMokZaWlo2qGrr2VRQFZ7WI3ILbW+VbItKFOvDdGTFiBHPmzKm2GIZhGIZhlIiILM93Loqi8g7c3igXenu1NAGfSkg2wzAMwzCMxMmr4IhIk4g0AV2BJ4BN3v/duFVIDcNox7Qsb2X67c20LG+ttiiZwtLFMLJBIQtOC06RaQE24JZEX+T9bklfNMOof2q5M5w5ayFPLtrIzFkLqy1KprB0MYzySaJtzKvgqOpIVR2F2zTuclXtr6r9gMtwe9C0O6rVGdVyJ2gUppY7wxlTx3L2mP7MmDq22qJkCksXo9bIYh+TRNsYxcl4iqp+0P+jqg+LyLdLfmIN4yc4wM/ff3rdP9dIH78TrMXOcOLwvlYeQ8hNl5blrcyctZAZU8cycXjfKkpmGOFksY9Jom2MouCsEZEv4DaKA7gGWFPyE2uYanVGtdwJGoUxJaH+yWLnYRhBstjHJNE2Ft1s03Ms/jJwNqDAk8BXVHVzWU+uMpMmTVKbJm4YRtqkacEx65DR3hGRFlWdFHauoAVHRDoCn1PVGalIZtQc1qAaRjzStNKZdcgw8lNwHRxV3Q+cVSFZjBqglp1ia41SHP+y6CxopIc5NBtZIYttT5SF/uaKyIMicq2IvNX/pC5ZxsnCjKpKyJD7DGtQ0yWY3qUok7nXZLHRMZLDtw6ZNdUoRNR2oJz2Iosvv1GcjLsCm4A3B44p8NtUJKoRsjCjCihZhuBQk3/fsGGn3HhW2ik2qpy1SNhwXzC9g45/+YYGc4/nOgvaEIZhGFHbgXLaiyw6KhdVcFT1vZUQpNYolJlp+qmEPbdYgcqVp2V5Kx+441lad+49GObJRRtp27WXXo0Nh8ld7UKblEKXRcIak2B6B5XJ6bc3h8a9mAJa7fyrB5Kuz+bHVt9kMX+jtgPltBdZnBFaVMERka7A+4ETcdYcAFT1fSnKlXkKZWZab81hFafQ/f3wba/vY97KLQfDz5y1kNade+nbreGwgtz2+r7DrAf+s6pZaEtR6GqFsLjlK1f5Gp5iDVIWG51aI+n6HOV+WewkIbtyZYksWk2jtgP11l5EGaL6BbAAuBD4Cm4dnJfTFKrWmTF1LG279tL2+j5alrcm1hDErTh++PFDeh/mN5NrJfDvF2y8slJJcytcFIWuVhrfOI1JvrD11iBlkaStYFHul5X6l0tW5coSZjXNDlHWwZmrqqeKyAuqeoqINABPqeqUyoiYDmmvg+MPKZw9pn+shqBQJx23Ay+nwy92bRaViVLT3DCyRhbrF2RXLqM+iOprGKTQOjhRZlH5jhpbROQkoDdwdGniHxToShF5SUQOiMiknHOfFZHFIvKKiFwYOH6Rd2yxiFwfOD5SRJq9478Rkc7lyJYUpc42KuSJHnfGRKkzLKI0YlnymPc9/y86aRDjh/Q+aDlL6r5pzECy2U31R1ielprPWZ0dlVW5agGr88XJ16+U2t9EUXBuFZG+wBeBB4F/At+K9ZQjmQ+8Fbcq8kFEZBxwNc7f5yLgRyLS0Vtw8IfAxcA44J1eWDxZvquqxwKtOH+houzcsz/VaXOlNgSlKEa5MsaROSxslKnGWZou7sv7p/lr6dXYwLyVWxJRvNJU4rKiIFqjG04p6RKWp0nls+VT7ZOVOp8m5ZbTsH6lZXkrbbv2Mn5on9j9TZRZVLd5P/8KjIp19/z3fBlARHJPTQPuUtXdwKsishiY7J1brKpLvevuAqaJyMu46evv8sLcAdwA/LiYDK+1vZ76tLlSiOJTkWthyZUxjszFZvLkC5Ml349CjsjlmNT9e1x00iCm396cqFk+6XH6sHjGscSB+VQEKSVdCpXDcvM5S/lkw1T5KZQ27cE3xy+nYTNyoxDWr8yctZB5q7Zy9pj+sctblFlUS4DZwFM435uXYj0hHoO9Z/ms8o4BrMw5fjrQD9iiqvtCwh+BiHwI+BDAwMFDilogytEc0yS3sQtzHg5+FyLKTJ5qV8xiDWohR+RyOgb/vvmmaMchNw6lKoj50iIsnlHiXu28zSqlpEtYnib1IlCNfPLL2kUnDeJP89fmfaEyDlEobbL0UpgWfvkMzsgtN87llP0oQ1TjgFtwysRNIrJERO4vdpGIzBKR+SGfabGlTAhVvVVVJ6nqpMEDBxy2xkjY8I6vOfbq2ilTbypBM15YhxdneCw3bJiJsdrj7uWYdpMYSkviHkmZp/PdJ0zGKHJXO2+zSFoWinKGkv1FHGfOWlixYSq/rN30yILDylyWhqejksYQX1h+ZvGFuJL47ckXLxuXWBkp1Ea1LG+lU9PgMfmujTJNfD/O0Xg/cABY730KoqpTI9w7l9XA0MD/Id4x8hzfBPQRkU6eFScYPhKFhney+nYbZQG4Usni21m1F59K4h5JlaV890nTetDeSKsOlDOUHLy+kPk/ydmPwSFa34IDtVmuysnTqFbTcoZS6o1KlZGZsxbSoXNjr7wBVLXgB9gJNANXAf2KhY/zAZ4AJgX+nwg8D3QBRgJLgY44RWypd6yzF+ZE75p7gKu93z8BPhrl2RMnTlRV1TnLNuu1t83WOcs2h/5PmuD98/0Ohp32g6d02s1P55UnaXnz3S/Oc6Lco1Jyp3VdudeWcr+0y6bhKCWdo1yTW5/jPscPP+3mp3X4Z/6g1942+4gw1942O++5KOdrlShtaal1J1+apdF31FMdr0Rc5izbrJ2aBm/VPP18lHVwpuF2FJ8M7AH+Djypqo/FVLaC97wC+AFwFLAFmKeqF3rnPg+8D9gH/IeqPuwdvwT4nqfw/K+qft07Pgq4C2gC5gLvVuekXJBJkybpLfc9GultJupbT5RwwbVagNDfYdaZKGu7tCxv5au/fwlE+OJl48peRyef3MXkyBc2X9yT0PRLXQPHv65vtwZuu+60WOniXzt+SO8j3qhLSeticUhynZ9iZaW9UW565OZNvvwPy8O4zy5nrax6zfewtqVnl46MPrpn2fEsd8gyzvWltEdpO32HbfUTpZ/xV9BPel2yXHnKWgdHVX+nqp8CPgw8BLwH+EM5Aqrq/ao6RFW7qOoAX7nxzn1dVUer6nG+cuMdf0hVx3rnvh44vlRVJ6vqsap6ZRTlxieqX0SS4YLj1/l+B8OOH9I78piubyLNN026Ur4s+cIWi285lHq/GVPH0rdbA60798ZOF/+ZiMSaHpzPH6BYHJJMs2JlJYx6nqocNz1y0yI3b4r5Svkz84K+fvmenfusfP44UTq6icP7JrqUQjUotmyFX6e37d5fNJ5RynSYD0icuhCn3S2lPUp7+nnu/aP2M6im4qsVJ74db7jhhoIBROS+G2+88Ru4WUtrgJnAv91www37Cl6YcW699dYbvvbZT7Bu6y5mTB3LMX0a84Yd1q97WeFalrdy/X0vMKxfdyYO78sVE4ZwTJ9GjunTGPrb55g+jVw9eRhXTx5W8LnB5y9c18bA3o18+qLjj7gmajzCCJMvbthi8S2HUu93TJ9GThvRVFK6+M8cM6DnEdcXSuvr73uBJxdtZN3WXVwxYUjkOCSZZsXKShj55K4H4qZHblrk5k1u/vttwJRR/fjYuccedNxduK6N3fsO0LNrA8OauoU+Oyzdox6Dw9ufY/o0HpTtopMGcdMjCw4eDwsbl3Kvj0JYPHPbltNGNLFwXRs9uzagwJgBPUPlCd5rWL/uB2Vfu/X1gvHId11Y2DjtbintUTntehRy7x+1n/n0xSfwsXOPTVymXHluvPHGtTfccMOtYWGjDFFNAuaq6v5EpawyaW/VECSq+drITz2lWa3GpVblToO4aZGvDYhixi+2xhEQOp0737MLHS93GLQS26XEGaIrJk/Y/nvFhtBzh2iC15UT50rUr3xT/2uNYFpNGtGUd4gqyiyqfwKfFZFhqvohERkDHKeqZQ1TtSdyZ75kcaZS1qnFNMvXYFVjFkoSs2tqcfZMWsRNi9w2wL8+V1GJ+qw4MynzzbwLOz5javhGwVF9e3bs2Z/6NOlg3IstepobHzhSGfSVm4tOGgS4WWN3P7sibzxyZ0slMUOyZXkrH7jjWVp37j0oexr46fPi6q2pPytI0spbMJ8LEUXB+T+gBTjT+78aN3PJFJwI5DZg/p5JkMxqu1kl6TiFNSJpplvce4eFr5RSlsSKxWlMozUOkU8hqsQSBHGe7fvo+D4OUReN9Dt9oCLTpHMtYHBIOQsqJrnxAWeZ+fuSTew7cGj0Ihi36bc3F5zunU9ZLTcerTv30rdbQ1FFKanV2YNT/9Mm6bYwmAe/KBAuioIzWlWvEpF3AqjqTgnZY8EIJ1fTDMvkWrFOhHnT56toSccp3xLeYc+I6/UfRqlrlATDBxuTJLd6KPbWGkaxTrDQ+WINatrlNykFql4VsaQta2FWnCjlp23XXhBhxtSxqc/W8svc+CG9Dzqy5luHJld233qRq0z4coct1pdbdqKmd7HhNN9qE4xHrjNzki9OQdnfdfqwWNeWQnBIDApbueLUz6h5EEXB2SMijYACiMhoIPJMpXokakefr7L4Fcm/JgkTZyXIrViFKlq+OIWl1bXXwrp1MGkSXHopjB4N27ZBW5v7/P3v8LvfwcsvQ8+ecMYZcNFFcNVJx7F3dwcuGnQczz0Hr70Gf/0r3P3X/bzWNoTnH9zBdef05Y6/7mAN3Wjot51v71/CJy8fzQ/+Urgixc2TsPB+JUxrMUZ/wbcojUexBqHQ+WINatrlNykFqlZeJJKkFKUuzIoTpfw88PGzDv73rSDAYZagpGQNljk/bL5ymCv7bdeddsRzgsN9YUpSqWWn0HUzZy08qGh98fITI7881Ep/AfHSLY36GcXJ+HzgC7gtG/4MvBF4j6o+kYgEVaIcJ+Ncx7U4TnxRzmWVOBacsPAQHu9PfAL+/Pg+Xp7fAd0fvnLBGWfAlCmwaRM8/jisXBkajIYGOHrgfra+vpcdG7ugKogoqgGjoygduuyle88DHD+iK01N0NQEw4fDaae5z5AhsHMndOwIqk556tPHfcpNt3KJu85EJdfxSAOz4JROqe1MEmUmrgWnnDWpfPbtg7VrXTvRtSvs3u3q7rhx7iXqhRdc3Z4wAfr1g9yxiDDn7Y+dM5ZVyztwx9+X84YuoxkzsDuNjdDYCC+t2M6vH23l4olNXHVZd557zj132zY49VRolS3c/rclXDJ8DOMG92LdOjj9dBgwoHAa793rZH926RZufWoRn7zs2Joss3HKUallrtA6OEUVHO8G/YApgACzVbW4d0/GKUfBiWPBiertX4/kW9QsLN7Tb2/miflbGLl7JO88ZSw9e3Lwc/zxMGjQofuqOmvOI484JWTsWKeI9OoFZ54J3bq5cKtXw4ED0L8/LFoECxbAmjXw0qu7eGxuK3t3NTCsex/27Wpg0yZYvtw1kHCocezSxTWCu3a54wMGwNSp8OEPu+ceffSRjWSliFq+kprlkTWyUoey5AtWadmSHIZqXtzKdd99mdaNHTm2e3+++Z7RNDa6enniia6+NS9u5TsPLuPdp43iL39q4N4H99J1Tw86SUd27nRKzIED0Z7ntxk9esCIETBsmPvdrZv7/PaZtby6qBPS2ptdWzuXFbdcTj4Zzj0Xund3bU3//k4R27MH5syBxx5z7RxAhw5wzjkwZgxcdZVTrAYPdvIaCSg4OTcbC3xKVT+YhHDVopLTxKtJNTuBOA1gWlaOfEpnmPXj9dfh+efh2WdhxQrX2G3e7BqaN7zBvRXOnw/33usUK3BhRo92jWVjI5x9tmuM1q6FxYudVej0053i1L//kY1SW5trkEuxDBUiqFz6Sk69KQJJWEGTkClNa2zSq1cXmm4eN/5RV1pvWd7K9x5dyJXHH8/+Db2ZNw8WLnT1rbOnN6xfDy++6OpYPkRAUQhYYxuO3sqgoft449h+dO3qOv6hQ11d273bKQf9+rkXnF/NXcxSVjKu10AuGXwC85fu4m8vbeXYvn3Zur4Lq1a5eu1/OnZSeg7awakndubqKzpz25OvsrLrciaP7MNXLx/Pzp2waEMbD61cwKXDjmfr8l6cc46Tq7HRWYvWrHH3Ou442L/fWYr/9jf4859h9mxnqdkXWFGuUycYORLe+lYnd0ODU9pmzXJptm3bobBDh8KoUXDllS6+nTq58N27u/8nn+ziX+8UUnDy+uCIyCnAfwPHAA8APwRuxi34950U5KxpSp2Gm7YCkjuuWUmFJ9+MjHxh09zYMPd40KnPp2tXp4ycXkSM73wHmpthyZJDnwMHoLUVbroJvvlNF07k0FsYuAboggtco7Rtm7vHggUu3FlnOUXphRfc2+T73udM6YMHu8YqLjOmjuXAfpjcMI5//L4nb+p2OlsWw+6Bzir12mvu2W1trgFuanLPHzXKvUXu3OlknDv38E+vXnD99fC2t7n7qDpl7skn3TVvfKNrzMOsWmF5ksSMkHJ8EZIY90/TJyLJe4fFtZz45zoWg6sH69bBhg3uZWHuXPj1wx3ZsGwCd+5uAFynO2KE64j37HFl6Oij4ZJL4MILYeBA9yLw6quwdavr8F96yb0wrN/+Os9vXMebjhvAWefu5e4FC7yyU1jWqVNh8vJ+zJy1iRlTBzJxOEy//QVe776RpjH9+UNO3FVBVejQocfBY6ee34eZs9YzY+pwTvKeN5leXMPk0GeOHBkuy7/8i6tDPq+/7hS7gQPdi1IYLctbuenBJZze7XiOP6YHS5bAP/7h0vfjHw+/ZvBgePvb4Q1nt3F3ywrOGzaC86f0YOVK19a1th566RoyxOXXxo2uDTr6aHd82DAXZuNGJ9vIkYeUpgMHylOgKtEX5bXgiEgz8GPgH8BFwOeAO4AvqerrqUhTQZK24JS6j1DUN+1Spy3nLuhUad+falmQqqVQbt/u3sy6dXN+QwsWuDfTDh3gqafgiSecyb1rV5g82X3274fbb3eN+RlnOAvS5s3ufl26wHXXwRVXuOu2bIFjjnENzeDBfkPsPr17u/svXuwazF/+0nU2uQwY4M7vC1mLvE8fp6js2XPomIgbHjj1VNf4/fOfLj6dO7vGOZcRI+BDH3JK0NhAvxzVJ6uSZGWYKw1y/UnCrKnlxn/zZlfGH3vMle8FCw73j2tshNHH7WNP70287YIevGVqd046ydWPatXROM/JSvnIV09UYelSZ636zD0vMOfVrZwyoB/XnDiO+++Hhx46vC7no1On8PYgl9694YQTYNUq9+nRA847D/71X517wOLFrs1Zv959WltdWzd6tHMzGDjQ/R4+HN77s/A4xU3zkoaoRGSeqo4P/F+qqqOKJ0FtkLSCk4QFp5CvRNyOIF/4JCpsXGfjJKnms6PIVopPQsvyVr7354V8/M1jOX10X3bscOPwGzfCo4/Cz37mGrA4NDS4N+Jrr3XWod27D71Rr1zpLDbnn+98nPyhuHnz4JVX3Jv1gAGuYRo/Hk45xYUB99bmd2a7drmwffq4t9IePdzxX/zCWXTAOXeed557Q9y82TV4kye7Ybxjj03GT63aw7BZKX+5JLW5raorM0uXOmvlo4+6jmzJEqdw+0yY4BTvlV2WsXTbZs44rRP3f+6Uw6wS+dq74MtdNXzGCvkGlipLkmUjzkKL3bt0Otj+bNoEt9+znYfnr2H6mwfSeVcvRo1y7UFTk2tjFi92iunAsduZtWQFn58+iOE9+7JihRuq37ABjjrKc3p+1rURw4Y5JeW115wStWrVkTL37Al9+7oXpo05XrsdOh2ga9MuuvbYzzuuaGDGBxoZO9a9OF3702aeXLSJs0b358vnTqapyb2Qbdzo2phevdxLV+fOTmnq0KE0BWcB8E6cYzHAL4F3+f9V9bmIeZNJklBwKuU3Usqz0lQEos4iS4NqPruYD0PQ3B9HnmJxWL/e+RAMHOgUjzVr3P8NG1xF9z++mfv88505OQm/nlLLzYoV8MADcP/9Tlnbvt29JfbocahT7N/fKVHDhrkhhMZG92Z/9tmuo5x+8/M0v7STMT2O4qPnHkuno7byu6UL+MSFyXVC5ca92haoQoTNCCoUF1VnTZwzx/mIvPqq+7z8siuDPkOHurf4Y491b+NjxrglHvyJAIXSLZ/FOkzZ8a3PldhWIOoLYZz6UI120d+os5Rnliqvqnt5mjPHvdAMGeIUosbAFlRtbTD95nnMfmkXnXf0ZOu6RvZt6Ua3vT3YuLQn4JQb3xoNHDn7NYQePWD79tIUnMcLxkn1zQWfnHHiKjhZNK/HIU1nxfZiwSm2d8+MqWNLtuDUghWgHEtgW5trwBZsbOWrv1zB2L1j2LauG3v2OKvSvHnR5JFO+xkwZjvfv7E3I0Y4BWlp61Z+9MfV/PtbjuHSM5Lz1o4SdyiuOGSBjRvhuefcm/rjjztn+T173Fv5gQNOIc4dzvSHQseMcUsndOi7jT8sWMYN7x3CpBHx4hocMr/72RUHLQ3vmDQ0VIkJLoLnd9o9u3Rk9NE9j6hbaVil8xGnHU3DAllsJKAcZbDQC1wSSmZuGfDbyaM79OVPf3JD8B06uBchEeeAPXKkazv693efF5Zt54Hm15h6wkCOauzOyy/Dj36U4CyqeiGughNnynMWyaKsWZSpEGFDULUWhygE4+l3QPlM9+OH9KZXY0PkRjzf2j1797rP5s3Oj2jtWtfBDhrkvvfuhftn7eCuh9vY9OIA1q8L926cNMnNeLvwQnjTm9ybZJgc5XQmWXqx2b/fKSxz5zqL3aBBrkMYPtylZXOzW06hpeXQm/GoUS6dunVzPl7gFJ2hQ52iM3q086no1evwZ5UzMy9oYRjer/vB7RXyWRz88D27dGRg70bWbX2dbbudk0ic9caSJo36Hkf+Spe9JCxDaY4eQImzqIzDCZvNkPTMnzTJoqxJzGCpJGGzwqqVrmkqVjNnHdpXqFfXTgdn3wW3m/DrQdvr+yLlYaHZa+B8hhoaXKf77neH3+Pkk7vzpU90Z88eZ/FZv9515jt2uA69udkpR/fd55y2wXXaZ53lhu6OOw5ue2IrSzb2YNOyVdz16b5s3+5M6WHDefnyNsmZTbt2uSnAzc1OhvPPdz5P+/a5IcfWVqec+J+NG53Stnr1oXRbsCD//Tt0cI7rN97o/KRGjSp9/ZRgvOPW3RlTxx7cImF4kzJ+SO8jFOiwZ/kK8fghvd2JwIytMLnSJo36Hkf+SsY1+Jxy9q5Ksp2PG3+z4NQo9WA5qMU4ZEXmNN/kwhwW8zl+JmWGTzJd9+1zCsPs2fD0084/YO3a8Blf4KwWp57qrB/jx8YLJ9UAABRDSURBVMMHP+gcqefPd9agPn3cdiEjRrjZbM3NbjjnuOOcz0H//s6SsmyZG+4ZOtQpIP36uWsXL3ZWlt27nULSoYML+8wz8Je/HJpu6y9Q19joho/27z8ko+/wffTRzjIzdKhTftavh09+En63cQ5Pzd/GyX2P5qZrTmT1avfsceOOtMQkQSn5ZQuixqNe4p72bLVEF/qrF2pdwUm6g6uXytReKDW/SnWSjDskUeqzylmmvxB79zplwJ/a/vTTbmZQr17ue84cNyPkhRcODeU0NLjrwClBQYUjSPeeyr49cnCmW3DKra+Q5E7B7djRWVKuvtqtHXTBBc4685M7d3DPo22ceXwfJhzfSI8eTvk64QR333yUOwmhmmRpyC9LtKd0yY1rnEUpyxqi8nYOvwYYpapfEZFhwEBVfSaRmNU41WookjZVZmW4KEsNb5Yp1VQeJ5+DZayU58V9lj+EEZxZk1Q5aGhw6wb5jD2zlYe9+38kcP9nnnErzU6a5BSPf/zDzVa79FJnhfnMLStZ22UVZ76hK23rGnnu+QMM6NiXy08dxPHHuymxK1e67UVee81Nre7bFz7wAfe9e7f7jBhx5CJpgwbBq03z2TlhI3vG9OejMdI7N3+K1aPcvKlmvav0sEst0LI8fKPmpO6dhEUlyTKTWwb88ulvKFzKsChE88H5EXAAeDPwFWAbcB9wWsw41CXVUgySHgvOSiOTZnqWM0ySVGVOsyOJcu84+VxuGYv7rOAuz0mXg9y0yXd/f/FFnze+8dDvCy6Afsf1YOasDsyYOgLwZ1ANothKulFJqh4WS798HUq+8GmSRf/AauP7weXuap7UvXOVh9xnRCkPSZaZ3DIQ5uNXUt1Q1YIf4Dnve27g2PPFrsv6Z+LEiZrLnGWb9drbZuucZZuPOJePUq6pFaoRtzSfee1ts3X4Z/6g1942O/J5X55pNz9d8NqkZMjqvcshbp7OWbZZp/3gKZ1289OJlYPctEmrnGWlPSglzbMgt+GIkh+l5lmUNi2t56dRLoE5mqefL+qD423ZcCbwrKpOEJGjgD+r6qnR1ajsEeaDk6UxzywM1WQpPZIgqgUnOGMgOPsnynTocmUoh6yu6JvEKtzlxq1SadPe6kzUMEbylFvWqpFvadSPcqeJfx+4HzhaRL4OvB34QpkCXQncAJwATFbVOd7xEcDLwCte0Nmq+hHv3ETgZ0Aj8BAwQ1VVRJqA3wAjgGXAO1S1tRS5sjJMA9nwiSklPbLc2BUzhfvng7sk5/qhpC1DVu9djELlNW45Cgtfbn2oVNpkoQ1Jsg5WeqjCiE65Za0a7UXF60c+007wAxwPfAz4OHBClGuK3O8E4DjgCWBS4PgIYH6ea54BpuC2ingYuNg7/m3geu/39cC3osgQNkSVFdIw0VeKrA6ThJHP/JmmebheSdtcbekdnSTrYLl1wfLNSBsKDFHl3excRJr8D7Ae+DXwK+A171g5StXLqvpK8ZAHZRkE9FLV2V6Efg68xTs9DbfLOd73W0JuUTH8BdFalpdkRAIOOZj16topc1aQYsyYOvaIhdySSJM08N88Z85aeNhx/82mUNrnuxayG980iZJmuRRKwyTunwS1mJdhdbBUoqR7oTBx8tjIFrVY9nPJq+AALcAc73sDsBBY5P1uSVGmkSIyV0T+KiL/4h0bDAT3K13lHQMYoKprvd/rgAH5biwiHxKROSIyZ8OGDYkLDslU6CQbqEoT1thlVRkoJ50LXRuMbz00EmkRRRmOm35Jp3ctdtDVUgbDqOW2rD1QqL7UYtnPJa8PjqqOBBCRnwL3q+pD3v+LiWAlEZFZwMCQU59X1d/luWwtMExVN3k+Nw+IyInFnhWQWUUkr9e0qt4K3ArOyTjqfeOQxBhjvU2bLJQmtTo9tdC1wfiaf0J+wtIwN73ipl/S6Z0Fn5pKkYb/XL21ZeVSCR/FOM9I0ncui0RxMp6iqh/0/6jqwyLy7WIXqerUuMKo6m5gt/e7RUSWAGOB1cCQQNAh3jFwQ2aDVHWtN5S1Pu5zk8Qq9JFEVQZyybLDciGC8a2HRiIqcVYfzUduekVNv+AMuLZde2l7fR+/al4RulFoHJnaU302ZTw9cjebhfTSuNTFPHOph7IfRcFZIyJfAO70/l8DrElDGG8K+mZV3S8io4AxwFJV3SwibSIyBWgGpgM/8C57ELgO+C/vO591KBFqtdPNKoUqUb6KmkYepJWv9dBIRCWYX771KqxBL5TWuekVNf2Cz/Y3RF2+aQetO/cesaCZdeThtCdlvNIU22w2SSq5mCdku0+MouC8E/gybqo4wJPesZIRkStwCspRwB9FZJ6qXgicDXxFRPbiVk/+iKpu9i77KIemiT/sfcApNneLyPuB5cA7ypENCmeYNY7lE3VtjXxLlaeRB5av5RM2NBfWoKeR1mGNur+eUe6O59aRh9OelPFKk/RyE4WodD5muu3MN70q9wP0BHpEDZ/1T6Fp4v40y/E3PlLSFGKjMFGmsRYKk0YeWL46kkqHLE0drpW8teUJjDSJWnbiLp9R7TJJKdPEfUTkZBGZC8wHXhKRFhE5KV21q7rMmDqWvt0aDm78FyRLMxRqlSgzKwqFSSMPgm897XnWU1IzJwrlUSXqUHB2SK3U2ShpXw8zW9o7Scz08+/xq+YVke8VtezkC1doWQ3falvJdtNPA+nc2D1fmChDVLcA/6mqjwOIyJtwM5HOTETKDJK78V+9Uq2x0ygm1GqZy6OYW7M85lwu9TJ8E8dsnpX8jJL29ZI/7ZkkhnT8e7y4eiutO/dGulfUspMvXNZmw/rP7Nij6Zh8YaLsRfW8qr6h2LFaI2wvqvZGVvbNyd0DKrgXVJb2VPLJSrrlIysddjWJkwZZz0+jvkiifobtm1fqTMEkqEab4z/zzo+eu+DA7p0nhIWJouDcDzwH/MI79G5goqpekai0FcYUnOx0hH4H4w8L+t9Z7XDSTreW5a189fcvgQhfvGwcQKznpd1hZ6XcJCVLluJjGElQS0p7ufWv3M023wfcCPzW+/+kd8yocZIeBiq1oPomzzALThZJY/gsmHb+Vh3AwfHuOObftIcxipmjK7kDdRKm8Sj5aUqQUUvU0lBmmsNbRRUcdTtz/zuAiHQEuqtqW6JSGHVBqQU12MG86/Rhh323F3LXkGnbtRdEDmugojZWafsvFVuc8QN3PFvULyCpRq1SDXkWp8Ka0mXko5am/KdZh6MMUf0K+AiwH3gW6AXMVNWbEpemgtgQVfJkrcHNmjyFqOQS7mn6OAWHG2+77rTULThp37Oce6edp7U0DGFUnlpq/8qh3CGqcaraJiLX4BbXux632WZNKzhGsmSxMmXxrTsflXjjyjfzIsm8i7qgWanxLaSkpZnfpchbqjxR86OWhiGMylNL7V9aFF0HB2gQkQbcBpsPqupeIJWNKqtFPez4XO04FFtjoRryRVlvpz3hp8enLjz+sHSJs7ZKsXxMe80ZX9abHllwhMxZy+9S5YmaH0mldbXbDiMdslYfqkEUBecWYBnQHXhSRIYDdeWDUw+LZ1U7DsUqUzXkq5UF3iqFnx7vOn3YYekSpyFMIx/jdLAzpo5l/JDe9O/R5YhtPJLI7yQ7+1LlqXTHVO22ox4pVo7ilLNSy2S1FuCLQ9rKdVEFR1W/r6qDVfUSb2Xk5cC5qUhTJepB0612HIo15tWWLwtk9U05TkecRj7G6WAnDu9Lr8YGFq3fTq+unRJXZrLQ2VdaMbe6mTzFylGcclZOmYxybTnKVrltWtr1La8Pjoi8W1XvFJH/zBPkf1KRqAoENd0s+ZDEoVpe81H9BWrJqz8t6mFMPI18jOtLEid83I1zi80Qq+U2Ih9WN5OnWBmNU4aDy2hMv705VvmL8pw47VJu2HLbtLT9yPLOohKRD6vqLSLy5bDzqnpjKhJViNxZVDYjoTSqlW612NlkXeasy1cKhcpn3PhaG2FUk7TKX5x6kBs2C21GoVlURaeJ1yu5Ck4WMqoWqVa6WWeTPPWYpkmWz/aw/L1RGpVc5sHKw+GUpeCIyChgJjAFN3vqH8AnVHVp0oJWElsHp7ZpL5W9kvFsL2laK9SjwlmvWF5Vj3LXwfkV8EPA33vqauDXgOWiUTXai99AJf122kua1gq2zk3tYHmVTaJYcF5Q1VNyjtlu4oZRAcyqYhiGkZ9yLTgPi8j1wF24IaqrgIdEpAlAVTcnJqlhGIdhVhXDMIzSiKLgvMP7/nDO8atxCs+oRCUyDMMwDMMok3Y7i0pEtgGvVFsO4yD9gY3VFsI4iOVHtrD8yBaWH9lhuKoeFXai0EJ/n1bVb3u/r1TVewLnvqGqn0tezorySr5xO6PyiMgcy4/sYPmRLSw/soXlR21QaKuGqwO/P5tz7qIUZDEMwzAMw0iEQgqO5Pkd9t8wDMMwDCMzFFJwNM/vsP+1yK3VFsA4DMuPbGH5kS0sP7KF5UcNUGgvqv3ADpy1phHY6Z8CuqpqQ0UkNAzDMAzDiEm7nUVlGIZhGEb9UmiIyjAMwzAMoyZpdwqOiFwkIq+IyGJvhWYjIURkqIg8LiL/FJGXRGSGd7xJRB4VkUXed1/vuIjI9728eEFEJgTudZ0XfpGIXBc4PlFEXvSu+b6ImMN7EUSko4jMFZE/eP9Hikizl4a/EZHO3vEu3v/F3vkRgXt81jv+iohcGDhu9SkGItJHRO4VkQUi8rKInGH1o3qIyCe8tmq+iPxaRLpa/agjVLXdfICOwBLc6sudgeeBcdWWq14+wCBggve7J7AQGAd8G7jeO3498C3v9yXAwzi/rilAs3e8CVjqfff1fvf1zj3jhRXv2ourHe+sf4D/xG2a+wfv/93A1d7vnwD/z/v9UeAn3u+rgd94v8d5daULMNKrQx2tPpWUF3cAH/B+dwb6WP2oWl4MBl4FGr3/dwPvsfpRP5/2ZsGZDCxW1aWquge3v9a0KstUN6jqWlV9zvu9DXgZ14hMwzXseN9v8X5PA36ujtlAHxEZBFwIPKqqm1W1FXgUuMg710tVZ6trWX4euJcRgogMAS4FbvP+C/Bm4F4vSG5++Pl0L3CeF34acJeq7lbVV4HFuLpk9SkGItIbOBu4HUBV96jqFqx+VJNOQKOIdAK6AWux+lE3tDcFZzCwMvB/lXfMSBjPfHsq0AwMUNW13ql1wADvd778KHR8VchxIz/fAz4NHPD+9wO2qOo+738wDQ+mu3d+qxc+bj4Z4YwENgD/5w0Z3iYi3bH6URVUdTXw38AKnGKzFWjB6kfd0N4UHKMCiEgP4D7gP1S1LXjOe7O0qXsVQEQuA9araku1ZTEAZy2YAPxYVU/FLcNxmF+G1Y/K4fk6TcMpnscA3bFV+uuK9qbgrAaGBv4P8Y4ZCSEiDTjl5peq+lvv8Gue+Rzve713PF9+FDo+JOS4Ec4bgX8VkWU48/ibgZm4oQ5/H7pgGh5Md+98b2AT8fPJCGcVsEpVm73/9+IUHqsf1WEq8KqqblDVvcBvcXXG6ked0N4UnGeBMZ6XfGeco9iDVZapbvDGo28HXlbV/wmcehDwZ3pcB/wucHy6N1tkCrDVM9U/AlwgIn29t6wLgEe8c20iMsV71vTAvYwcVPWzqjpEVUfgyvpfVPUa4HHg7V6w3Pzw8+ntXnj1jl/tzSIZCYzBObNafYqBqq4DVorIcd6h84B/YvWjWqwApohINy+9/Pyw+lEvVNvLudIf3MyEhTjv9s9XW556+gBn4czrLwDzvM8luHHqx4BFwCygyQsvwA+9vHgRmBS41/twznqLgfcGjk8C5nvX3Iy3WKV9iubNmzg0i2oUrgFeDNwDdPGOd/X+L/bOjwpc/3kvzV8hMDPH6lPsfBgPzPHqyAO4WVBWP6qXHzcCC7w0+wVuJpTVjzr52ErGhmEYhmHUHe1tiMowDMMwjHaAKTiGYRiGYdQdpuAYhmEYhlF3mIJjGIZhGEbdYQqOYRiGYRh1hyk4hmFUBW9n7Y96v48RkXuLXVPGs8aLyCVp3d8wjOxhCo5hGNWiD26HZlR1jaq+vUj4chiPW5PEMIx2gik4hmFUi/8CRovIPBG5R0TmA4jIe0TkARF5VESWicjHReQ/vQ0qZ4tIkxdutIj8SURaROQpETneO36liMwXkedF5ElvFdmvAFd5z7pKRLqLyP+KyDPefacFnv07EXlCRBaJyJe9491F5I/ePeeLyFVVSTHDMCLTqXgQwzCMVLgeOElVx3u7z/8hcO4k3G70XXErx35GVU8Vke/itiD4HnAr8BFVXSQipwM/wu239SXgQlVdLSJ9VHWPiHwJtxLwxwFE5Bu4pfbfJyJ9gGdEZJb37Mne83cCz4rIH4HhwBpVvdS7vndaiWIYRjKYgmMYRhZ5XFW3AdtEZCvwe+/4i8Ap3o71ZwL3uG2EALfMPsDfgJ+JyN24DRTDuAC3Eeknvf9dgWHe70dVdROAiPwWtwXJQ8B3RORbuC0vnkoikoZhpIcpOIZhZJHdgd8HAv8P4NqtDsAWVR2fe6GqfsSz6FwKtIjIxJD7C/A2VX3lsIPuutz9a1RVF4rIBJwfz9dE5DFV/UopETMMozKYD45hGNViG9CzlAtVtQ14VUSuBLeTvYi8wfs9WlWbVfVLwAZgaMizHgH+zdtFGhE5NXDufBFpEpFG4C3A30TkGGCnqt4J3ARMKEVuwzAqhyk4hmFUBW8Y6G+ec/FNJdziGuD9IvI88BIwzTt+k4i86N3378DzwOPAON/JGPgq0AC8ICIvef99ngHuw+34fZ+qzgFOxvnpzAO+DHytBHkNw6ggtpu4YRiGh4i8h4AzsmEYtYtZcAzDMAzDqDvMgmMYhmEYRt1hFhzDMAzDMOoOU3AMwzAMw6g7TMExDMMwDKPuMAXHMAzDMIy6wxQcwzAMwzDqjv8PZxrD8gyZxpYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 26s, sys: 6.34 s, total: 1min 33s\n",
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "envname=\"Pendulum-v0\"\n",
    "env = gym.make(envname)\n",
    "exp_name=env.spec._env_name+'-PPO2'\n",
    "\n",
    "#train\n",
    "log_dir='logs_train/'+exp_name\n",
    "env = Monitor(env, log_dir, allow_early_resets=True)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "\n",
    "model = PPO2(MlpPolicy, env, verbose=0)\n",
    "\n",
    "print(\"time_steps_todo: \"+str(time_steps))\n",
    "model.learn(total_timesteps=int(time_steps))\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "model.save(\"models/\"+log_dir.split(\"/\")[1])\n",
    "\n",
    "copyfile(log_dir+\".monitor.csv\", \"logs_tmp/tmp.monitor.csv\")\n",
    "results_plotter.plot_results([\"logs_tmp\"], time_steps, results_plotter.X_TIMESTEPS, log_dir.split(\"/\")[1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.67 s, sys: 93.6 ms, total: 2.76 s\n",
      "Wall time: 1.82 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#test\n",
    "\n",
    "env = gym.make(envname)\n",
    "log_dir='logs_test/'+exp_name\n",
    "env = Monitor(env, log_dir, allow_early_resets=True)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "\n",
    "model = PPO2.load(\"models/\"+log_dir.split(\"/\")[1])\n",
    "obs = env.reset()\n",
    "for i in range(time_steps_test):\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    #env.render()\n",
    "    \n",
    "copyfile(log_dir+\".monitor.csv\", \"logs_tmp/tmp.monitor.csv\")\n",
    "results_plotter.plot_results([\"logs_tmp\"], time_steps, results_plotter.X_TIMESTEPS, log_dir.split(\"/\")[1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_steps_todo: 100000.0\n",
      "Track generation: 1027..1288 -> 261-tiles track\n",
      "Track generation: 1233..1545 -> 312-tiles track\n",
      "Track generation: 1269..1591 -> 322-tiles track\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/qlearning/lib/python3.6/site-packages/stable_baselines/ppo2/ppo2.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, seed, log_interval, tb_log_name, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0mcliprange_vf_now\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcliprange_vf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrac\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                 \u001b[0;31m# true_reward is the reward without discount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneglogpacs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mep_infos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m                 \u001b[0mep_info_buf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mep_infos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/qlearning/lib/python3.6/site-packages/stable_baselines/ppo2/ppo2.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m                 \u001b[0mclipped_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhigh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclipped_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minfos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0mmaybe_ep_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'episode'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/qlearning/lib/python3.6/site-packages/stable_baselines/common/vec_env/base_vec_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \"\"\"\n\u001b[1;32m    133\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/qlearning/lib/python3.6/site-packages/stable_baselines/common/vec_env/dummy_vec_env.py\u001b[0m in \u001b[0;36mstep_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0menv_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuf_rews\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuf_dones\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuf_infos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuf_dones\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0;31m# save final observation where user can get it, then reset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/qlearning/lib/python3.6/site-packages/stable_baselines/bench/monitor.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneeds_reset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tried to step environment that needs reset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/backprop q learning research/gym/gym/wrappers/time_limit.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Cannot call env.step() before calling reset()\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_episode_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/backprop q learning research/gym/gym/envs/box2d/car_racing.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mFPS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"state_pixels\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0mstep_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/backprop q learning research/gym/gym/envs/box2d/car_racing.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m         \u001b[0mimage_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_buffer_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_color_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_image_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVP_H\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVP_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/qlearning/lib/python3.6/site-packages/pyglet/image/__init__.py\u001b[0m in \u001b[0;36mget_image_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2153\u001b[0m         \u001b[0mglPixelStorei\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGL_PACK_ALIGNMENT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2154\u001b[0m         glReadPixels(x, y, self.width, self.height,\n\u001b[0;32m-> 2155\u001b[0;31m                      self.gl_format, GL_UNSIGNED_BYTE, buffer)\n\u001b[0m\u001b[1;32m   2156\u001b[0m         \u001b[0mglPopClientAttrib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/qlearning/lib/python3.6/site-packages/pyglet/gl/lib.py\u001b[0m in \u001b[0;36merrcheck\u001b[0;34m(result, func, arguments)\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mpyglet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/qlearning/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "envname=\"CarRacing-v0\"\n",
    "env = gym.make(envname)\n",
    "exp_name=env.spec._env_name+'-PPO2'\n",
    "\n",
    "#train\n",
    "log_dir='logs_train/'+exp_name\n",
    "env = Monitor(env, log_dir, allow_early_resets=True)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "\n",
    "model = PPO2(MlpPolicy, env, verbose=0)\n",
    "\n",
    "print(\"time_steps_todo: \"+str(time_steps))\n",
    "model.learn(total_timesteps=int(time_steps))\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "model.save(\"models/\"+log_dir.split(\"/\")[1])\n",
    "\n",
    "copyfile(log_dir+\".monitor.csv\", \"logs_tmp/tmp.monitor.csv\")\n",
    "results_plotter.plot_results([\"logs_tmp\"], time_steps, results_plotter.X_TIMESTEPS, log_dir.split(\"/\")[1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1151..1443 -> 292-tiles track\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/qlearning/lib/python3.6/site-packages/stable_baselines/common/vec_env/base_vec_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \"\"\"\n\u001b[1;32m    133\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/qlearning/lib/python3.6/site-packages/stable_baselines/common/vec_env/dummy_vec_env.py\u001b[0m in \u001b[0;36mstep_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0menv_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuf_rews\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuf_dones\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuf_infos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuf_dones\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0;31m# save final observation where user can get it, then reset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/qlearning/lib/python3.6/site-packages/stable_baselines/bench/monitor.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneeds_reset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tried to step environment that needs reset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/backprop q learning research/gym/gym/wrappers/time_limit.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Cannot call env.step() before calling reset()\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_episode_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/backprop q learning research/gym/gym/envs/box2d/car_racing.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mFPS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"state_pixels\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0mstep_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/backprop q learning research/gym/gym/envs/box2d/car_racing.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monetime_geoms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender_indicators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWINDOW_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWINDOW_H\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'human'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/backprop q learning research/gym/gym/envs/box2d/car_racing.py\u001b[0m in \u001b[0;36mrender_indicators\u001b[0;34m(self, W, H)\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0mgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglEnd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"%04i\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/qlearning/lib/python3.6/site-packages/pyglet/text/layout.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    895\u001b[0m         \"\"\"\n\u001b[1;32m    896\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_own_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_subset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vertex_lists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/qlearning/lib/python3.6/site-packages/pyglet/graphics/__init__.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdraw_subset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertex_lists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/qlearning/lib/python3.6/site-packages/pyglet/text/layout.py\u001b[0m in \u001b[0;36mset_state\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0mglPushAttrib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGL_ENABLE_BIT\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mGL_CURRENT_BIT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0mglEnable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGL_BLEND\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m         \u001b[0mglBlendFunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGL_SRC_ALPHA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGL_ONE_MINUS_SRC_ALPHA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0munset_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#test\n",
    "\n",
    "env = gym.make(envname)\n",
    "log_dir='logs_test/'+exp_name\n",
    "env = Monitor(env, log_dir, allow_early_resets=True)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "\n",
    "model = PPO2.load(\"models/\"+log_dir.split(\"/\")[1])\n",
    "obs = env.reset()\n",
    "for i in range(time_steps_test):\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    #env.render()\n",
    "    \n",
    "copyfile(log_dir+\".monitor.csv\", \"logs_tmp/tmp.monitor.csv\")\n",
    "results_plotter.plot_results([\"logs_tmp\"], time_steps, results_plotter.X_TIMESTEPS, log_dir.split(\"/\")[1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_steps_todo: 100000.0\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "envname=\"LunarLanderContinuous-v2\"\n",
    "env = gym.make(envname)\n",
    "exp_name=env.spec._env_name+'-PPO2'\n",
    "\n",
    "#train\n",
    "log_dir='logs_train/'+exp_name\n",
    "env = Monitor(env, log_dir, allow_early_resets=True)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "\n",
    "model = PPO2(MlpPolicy, env, verbose=0)\n",
    "\n",
    "print(\"time_steps_todo: \"+str(time_steps))\n",
    "model.learn(total_timesteps=int(time_steps))\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "model.save(\"models/\"+log_dir.split(\"/\")[1])\n",
    "\n",
    "copyfile(log_dir+\".monitor.csv\", \"logs_tmp/tmp.monitor.csv\")\n",
    "results_plotter.plot_results([\"logs_tmp\"], time_steps, results_plotter.X_TIMESTEPS, log_dir.split(\"/\")[1])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#test\n",
    "\n",
    "env = gym.make(envname)\n",
    "log_dir='logs_test/'+exp_name\n",
    "env = Monitor(env, log_dir, allow_early_resets=True)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "\n",
    "model = PPO2.load(\"models/\"+log_dir.split(\"/\")[1])\n",
    "obs = env.reset()\n",
    "for i in range(time_steps_test):\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    #env.render()\n",
    "    \n",
    "copyfile(log_dir+\".monitor.csv\", \"logs_tmp/tmp.monitor.csv\")\n",
    "results_plotter.plot_results([\"logs_tmp\"], time_steps, results_plotter.X_TIMESTEPS, log_dir.split(\"/\")[1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "envname=\"BipedalWalker-v2\"\n",
    "env = gym.make(envname)\n",
    "exp_name=env.spec._env_name+'-PPO2'\n",
    "\n",
    "#train\n",
    "log_dir='logs_train/'+exp_name\n",
    "env = Monitor(env, log_dir, allow_early_resets=True)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "\n",
    "model = PPO2(MlpPolicy, env, verbose=0)\n",
    "\n",
    "print(\"time_steps_todo: \"+str(time_steps))\n",
    "model.learn(total_timesteps=int(time_steps))\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "model.save(\"models/\"+log_dir.split(\"/\")[1])\n",
    "\n",
    "copyfile(log_dir+\".monitor.csv\", \"logs_tmp/tmp.monitor.csv\")\n",
    "results_plotter.plot_results([\"logs_tmp\"], time_steps, results_plotter.X_TIMESTEPS, log_dir.split(\"/\")[1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#test\n",
    "\n",
    "env = gym.make(envname)\n",
    "log_dir='logs_test/'+exp_name\n",
    "env = Monitor(env, log_dir, allow_early_resets=True)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "\n",
    "model = PPO2.load(\"models/\"+log_dir.split(\"/\")[1])\n",
    "obs = env.reset()\n",
    "for i in range(time_steps_test):\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    #env.render()\n",
    "    \n",
    "copyfile(log_dir+\".monitor.csv\", \"logs_tmp/tmp.monitor.csv\")\n",
    "results_plotter.plot_results([\"logs_tmp\"], time_steps, results_plotter.X_TIMESTEPS, log_dir.split(\"/\")[1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
